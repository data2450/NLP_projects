{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9501450,"sourceType":"datasetVersion","datasetId":5782495}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T15:34:49.885298Z","iopub.execute_input":"2024-09-28T15:34:49.885671Z","iopub.status.idle":"2024-09-28T15:34:50.244887Z","shell.execute_reply.started":"2024-09-28T15:34:49.885632Z","shell.execute_reply":"2024-09-28T15:34:50.243856Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"encoding = 'ISO-8859-1'","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:34:50.246748Z","iopub.execute_input":"2024-09-28T15:34:50.247344Z","iopub.status.idle":"2024-09-28T15:34:50.251971Z","shell.execute_reply.started":"2024-09-28T15:34:50.247288Z","shell.execute_reply":"2024-09-28T15:34:50.250927Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/hacke-earth-fibe/dataset/train.csv',encoding=encoding)\ntest = pd.read_csv('/kaggle/input/hacke-earth-fibe/dataset/test.csv',encoding=encoding)\nss = pd.read_csv('/kaggle/input/hacke-earth-fibe/dataset/sample_submission.csv',encoding=encoding)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:34:50.607275Z","iopub.execute_input":"2024-09-28T15:34:50.607642Z","iopub.status.idle":"2024-09-28T15:35:21.405414Z","shell.execute_reply.started":"2024-09-28T15:34:50.607606Z","shell.execute_reply":"2024-09-28T15:35:21.404592Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:21.407272Z","iopub.execute_input":"2024-09-28T15:35:21.407958Z","iopub.status.idle":"2024-09-28T15:35:21.430125Z","shell.execute_reply.started":"2024-09-28T15:35:21.407908Z","shell.execute_reply":"2024-09-28T15:35:21.429185Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text              target  \\\n0  python courses python courses, python exercise...  academic interests   \n1  the learning point open digital education. a r...  academic interests   \n2  tech news, latest technology, mobiles, laptops...  academic interests   \n3  the best it certification materials in usa | k...  academic interests   \n4  bioland scientific, for your research needs bi...  academic interests   \n\n   Word Count  \n0         125  \n1         147  \n2         143  \n3         364  \n4         176  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n      <th>Word Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>python courses python courses, python exercise...</td>\n      <td>academic interests</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the learning point open digital education. a r...</td>\n      <td>academic interests</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tech news, latest technology, mobiles, laptops...</td>\n      <td>academic interests</td>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the best it certification materials in usa | k...</td>\n      <td>academic interests</td>\n      <td>364</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bioland scientific, for your research needs bi...</td>\n      <td>academic interests</td>\n      <td>176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:25:19.209145Z","iopub.execute_input":"2024-09-28T12:25:19.209532Z","iopub.status.idle":"2024-09-28T12:25:19.216771Z","shell.execute_reply.started":"2024-09-28T12:25:19.209481Z","shell.execute_reply":"2024-09-28T12:25:19.215620Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(697527, 3)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:07:11.202975Z","iopub.execute_input":"2024-09-28T12:07:11.203479Z","iopub.status.idle":"2024-09-28T12:07:11.336349Z","shell.execute_reply.started":"2024-09-28T12:07:11.203433Z","shell.execute_reply":"2024-09-28T12:07:11.335113Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"target\nacademic interests                           58508\nbooks and literature                         40435\nhealthy living                               30945\ncareers                                      30484\nnews and politics                            30197\nshopping                                     29518\nstyle and fashion                            29144\nfamily and relationships                     28951\nbusiness and finance                         28038\nautomotives                                  28004\npharmaceuticals, conditions, and symptoms    26596\narts and culture                             26362\nsports                                       24541\npets                                         24136\nhobbies and interests                        23955\nreal estate                                  23845\nfood and drinks                              23434\nhome and garden                              23013\nvideo gaming                                 22950\nmovies                                       21781\ntravel                                       21697\npersonal finance                             21132\ntechnology and computing                     20741\nmusic and audio                              20630\ntelevision                                   19520\nhealth                                       18970\nName: count, dtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"pip install transformers torch scikit-learn\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:21.431689Z","iopub.execute_input":"2024-09-28T15:35:21.432329Z","iopub.status.idle":"2024-09-28T15:35:34.609041Z","shell.execute_reply.started":"2024-09-28T15:35:21.432271Z","shell.execute_reply":"2024-09-28T15:35:34.607900Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:10:55.026696Z","iopub.execute_input":"2024-09-28T12:10:55.027651Z","iopub.status.idle":"2024-09-28T12:10:55.049987Z","shell.execute_reply.started":"2024-09-28T12:10:55.027595Z","shell.execute_reply":"2024-09-28T12:10:55.048685Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                     text  Word Count  \\\n0       equl offers enzyme assay kits, reagent mixture...         353   \n1       gauthmath: instant math questions solver for f...         112   \n2       Whats the No. 1 cause of blindness in older ad...         340   \n3       Surfers will ride a wave in the Amazon this we...         465   \n4       Why is the top of a leaf the most colorful, so...         269   \n...                                                   ...         ...   \n174377  his story will soon pale in comparison next to...         119   \n174378  Mundo.Take a look at a gallery of covers below...         115   \n174379  may change over the course of the game's devel...         141   \n174380  Mark Gustafson. If you've already watched it a...         101   \n174381  Mann/Tomeu MoreyPoison Ivy #7 by David Nakayam...         160   \n\n                 Index  \n0            Article_0  \n1            Article_1  \n2            Article_2  \n3            Article_3  \n4            Article_4  \n...                ...  \n174377  Article_174377  \n174378  Article_174378  \n174379  Article_174379  \n174380  Article_174380  \n174381  Article_174381  \n\n[174382 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Word Count</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>equl offers enzyme assay kits, reagent mixture...</td>\n      <td>353</td>\n      <td>Article_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gauthmath: instant math questions solver for f...</td>\n      <td>112</td>\n      <td>Article_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Whats the No. 1 cause of blindness in older ad...</td>\n      <td>340</td>\n      <td>Article_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Surfers will ride a wave in the Amazon this we...</td>\n      <td>465</td>\n      <td>Article_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why is the top of a leaf the most colorful, so...</td>\n      <td>269</td>\n      <td>Article_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>174377</th>\n      <td>his story will soon pale in comparison next to...</td>\n      <td>119</td>\n      <td>Article_174377</td>\n    </tr>\n    <tr>\n      <th>174378</th>\n      <td>Mundo.Take a look at a gallery of covers below...</td>\n      <td>115</td>\n      <td>Article_174378</td>\n    </tr>\n    <tr>\n      <th>174379</th>\n      <td>may change over the course of the game's devel...</td>\n      <td>141</td>\n      <td>Article_174379</td>\n    </tr>\n    <tr>\n      <th>174380</th>\n      <td>Mark Gustafson. If you've already watched it a...</td>\n      <td>101</td>\n      <td>Article_174380</td>\n    </tr>\n    <tr>\n      <th>174381</th>\n      <td>Mann/Tomeu MoreyPoison Ivy #7 by David Nakayam...</td>\n      <td>160</td>\n      <td>Article_174381</td>\n    </tr>\n  </tbody>\n</table>\n<p>174382 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:34.614167Z","iopub.execute_input":"2024-09-28T15:35:34.614474Z","iopub.status.idle":"2024-09-28T15:35:35.215528Z","shell.execute_reply.started":"2024-09-28T15:35:34.614441Z","shell.execute_reply":"2024-09-28T15:35:35.214529Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:23:45.772731Z","iopub.execute_input":"2024-09-28T12:23:45.773340Z","iopub.status.idle":"2024-09-28T12:23:46.322103Z","shell.execute_reply.started":"2024-09-28T12:23:45.773290Z","shell.execute_reply":"2024-09-28T12:23:46.320097Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"],"ename":"NameError","evalue":"name 'train' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ntrain['category'] = label_encoder.fit_transform(train['target'])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:35.216895Z","iopub.execute_input":"2024-09-28T15:35:35.217873Z","iopub.status.idle":"2024-09-28T15:35:35.390097Z","shell.execute_reply.started":"2024-09-28T15:35:35.217825Z","shell.execute_reply":"2024-09-28T15:35:35.389359Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df_sampled, _ = train_test_split(train, test_size=0.8, stratify=train['target'], random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:35.391219Z","iopub.execute_input":"2024-09-28T15:35:35.391531Z","iopub.status.idle":"2024-09-28T15:35:37.090144Z","shell.execute_reply.started":"2024-09-28T15:35:35.391498Z","shell.execute_reply":"2024-09-28T15:35:37.089100Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_sampled.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:37.091465Z","iopub.execute_input":"2024-09-28T15:35:37.091810Z","iopub.status.idle":"2024-09-28T15:35:37.097910Z","shell.execute_reply.started":"2024-09-28T15:35:37.091777Z","shell.execute_reply":"2024-09-28T15:35:37.097084Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(139505, 4)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df_sampled['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:37.099089Z","iopub.execute_input":"2024-09-28T15:35:37.099368Z","iopub.status.idle":"2024-09-28T15:35:37.137357Z","shell.execute_reply.started":"2024-09-28T15:35:37.099337Z","shell.execute_reply":"2024-09-28T15:35:37.136413Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"target\nacademic interests                           11702\nbooks and literature                          8087\nhealthy living                                6189\ncareers                                       6097\nnews and politics                             6039\nshopping                                      5904\nstyle and fashion                             5829\nfamily and relationships                      5790\nbusiness and finance                          5608\nautomotives                                   5601\npharmaceuticals, conditions, and symptoms     5319\narts and culture                              5272\nsports                                        4908\npets                                          4827\nhobbies and interests                         4791\nreal estate                                   4769\nfood and drinks                               4687\nhome and garden                               4603\nvideo gaming                                  4590\nmovies                                        4356\ntravel                                        4339\npersonal finance                              4226\ntechnology and computing                      4148\nmusic and audio                               4126\ntelevision                                    3904\nhealth                                        3794\nName: count, dtype: int64"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df_sampled['text'], df_sampled['category'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:37.138498Z","iopub.execute_input":"2024-09-28T15:35:37.138871Z","iopub.status.idle":"2024-09-28T15:35:37.160629Z","shell.execute_reply.started":"2024-09-28T15:35:37.138824Z","shell.execute_reply":"2024-09-28T15:35:37.159909Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\n\n# Load the tokenizer and model\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_encoder.classes_))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:35:37.163417Z","iopub.execute_input":"2024-09-28T15:35:37.164047Z","iopub.status.idle":"2024-09-28T15:36:04.657810Z","shell.execute_reply.started":"2024-09-28T15:35:37.164005Z","shell.execute_reply":"2024-09-28T15:36:04.656873Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e1331100f645afa5a6f1890d78eb83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cd3337a4752422eb78965561cf4ee42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38e0a39e619b441596ab4660a9be41a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af360de28f3432ea76e0264a15f7dd4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e27e650b92e145db91918dd1f5b9ee3f"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:30:34.971383Z","iopub.execute_input":"2024-09-28T12:30:34.972506Z","iopub.status.idle":"2024-09-28T12:30:34.981298Z","shell.execute_reply.started":"2024-09-28T12:30:34.972443Z","shell.execute_reply":"2024-09-28T12:30:34.979941Z"},"trusted":true},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Index(['text', 'target', 'Word Count', 'category'], dtype='object')"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"train['Word Count'].describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:30:58.822309Z","iopub.execute_input":"2024-09-28T12:30:58.822766Z","iopub.status.idle":"2024-09-28T12:30:58.857080Z","shell.execute_reply.started":"2024-09-28T12:30:58.822722Z","shell.execute_reply":"2024-09-28T12:30:58.855831Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"count    697527.000000\nmean        305.898281\nstd         137.798053\nmin         100.000000\n25%         179.000000\n50%         291.000000\n75%         445.000000\nmax         500.000000\nName: Word Count, dtype: float64"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n\n# Tokenization (using batch processing for speed)\nbatch_size = 64  # Choose an appropriate batch size\ntrain_encodings = []\ntest_encodings = []\n\nfor i in range(0, len(X_train), batch_size):\n    batch = X_train[i:i + batch_size]\n    encodings = tokenizer(batch, truncation=True, padding=True, max_length=300)\n    train_encodings.append(encodings)\n\nfor i in range(0, len(X_test), batch_size):\n    batch = X_test[i:i + batch_size]\n    encodings = tokenizer(batch, truncation=True, padding=True, max_length=300)\n    test_encodings.append(encodings)\n\n# Combine the results into a single encoding\ntrain_encodings = {k: [enc for d in train_encodings for enc in d[k]] for k in train_encodings[0].keys()}\ntest_encodings = {k: [enc for d in test_encodings for enc in d[k]] for k in test_encodings[0].keys()}\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:34:58.781801Z","iopub.execute_input":"2024-09-28T12:34:58.782249Z","iopub.status.idle":"2024-09-28T12:34:59.075884Z","shell.execute_reply.started":"2024-09-28T12:34:58.782208Z","shell.execute_reply":"2024-09-28T12:34:59.074469Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_train), batch_size):\n\u001b[1;32m     12\u001b[0m     batch \u001b[38;5;241m=\u001b[39m X_train[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 13\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     train_encodings\u001b[38;5;241m.\u001b[39mappend(encodings)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_test), batch_size):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3055\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3055\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3114\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 3114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3117\u001b[0m     )\n\u001b[1;32m   3119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   3120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3123\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."],"ename":"ValueError","evalue":"text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T12:34:12.156678Z","iopub.execute_input":"2024-09-28T12:34:12.157139Z","iopub.status.idle":"2024-09-28T12:34:12.208332Z","shell.execute_reply.started":"2024-09-28T12:34:12.157094Z","shell.execute_reply":"2024-09-28T12:34:12.206689Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"],"ename":"NameError","evalue":"name 'AutoTokenizer' is not defined","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:36:04.659200Z","iopub.execute_input":"2024-09-28T15:36:04.659968Z","iopub.status.idle":"2024-09-28T15:36:04.798449Z","shell.execute_reply.started":"2024-09-28T15:36:04.659921Z","shell.execute_reply":"2024-09-28T15:36:04.797509Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Tokeadd_suffixnization\ntrain_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=300)\ntest_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=300)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:36:04.802710Z","iopub.execute_input":"2024-09-28T15:36:04.803018Z","iopub.status.idle":"2024-09-28T15:37:27.964270Z","shell.execute_reply.started":"2024-09-28T15:36:04.802986Z","shell.execute_reply":"2024-09-28T15:37:27.963393Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nclass ArticleDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = ArticleDataset(train_encodings, y_train.to_numpy())\ntest_dataset = ArticleDataset(test_encodings, y_test.to_numpy())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:37:27.965399Z","iopub.execute_input":"2024-09-28T15:37:27.965695Z","iopub.status.idle":"2024-09-28T15:37:27.973168Z","shell.execute_reply.started":"2024-09-28T15:37:27.965665Z","shell.execute_reply":"2024-09-28T15:37:27.972153Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=4,              # total number of training epochs\n    per_device_train_batch_size=58,   # batch size per device during training\n    per_device_eval_batch_size=58,    # batch size for evaluation\n    warmup_steps=500,                 # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,                # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:37:27.974849Z","iopub.execute_input":"2024-09-28T15:37:27.975189Z","iopub.status.idle":"2024-09-28T15:37:28.108823Z","shell.execute_reply.started":"2024-09-28T15:37:27.975157Z","shell.execute_reply":"2024-09-28T15:37:28.107821Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:37:28.110041Z","iopub.execute_input":"2024-09-28T15:37:28.110366Z","iopub.status.idle":"2024-09-28T17:27:41.891264Z","shell.execute_reply.started":"2024-09-28T15:37:28.110333Z","shell.execute_reply":"2024-09-28T17:27:41.890329Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240928_154420-6jqdongh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jojupattamana-kerala-university/huggingface/runs/6jqdongh' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/jojupattamana-kerala-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jojupattamana-kerala-university/huggingface' target=\"_blank\">https://wandb.ai/jojupattamana-kerala-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jojupattamana-kerala-university/huggingface/runs/6jqdongh' target=\"_blank\">https://wandb.ai/jojupattamana-kerala-university/huggingface/runs/6jqdongh</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3852' max='3852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3852/3852 1:43:16, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>3.265600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.268500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>3.256900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>3.254100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>3.238800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>3.219900</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>3.187100</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>3.146500</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>3.081600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.998200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.900700</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.849200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>2.680500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>2.583400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.435800</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.333300</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>2.211000</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>2.119900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.060200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.007800</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.865500</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.747100</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.689800</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.652100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.624800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.546900</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.426200</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.376100</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.357700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.361800</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.264800</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.248300</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.190200</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.215900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.232400</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.197000</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.159300</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.129000</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.117900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.103400</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>1.070300</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.119800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>1.106000</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.149700</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.094400</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.982700</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>1.100300</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.021000</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>1.061800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.941800</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>1.027200</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.985300</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>1.010400</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>1.083500</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.998400</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>1.047700</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>1.034100</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>1.039500</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.997400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.017800</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.946600</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.898400</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.965200</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.957800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.965700</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.975500</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.999100</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.904100</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>1.027100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.939000</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.908900</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.854500</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.887900</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.970700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.996200</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.939800</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.928100</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.841000</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.859300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.881100</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.913000</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.915800</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.912300</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.904200</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.902300</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.910300</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.904900</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.955500</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.910400</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.782000</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.822800</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.786100</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.913600</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.795700</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.796900</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.845900</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.758800</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.832000</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.781700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.731600</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.764100</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.767600</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.727500</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.793300</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.770900</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.693700</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.741400</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.775500</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.735400</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.754900</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.813100</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.766000</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.764800</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.675200</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.755200</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.784700</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.740200</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.781800</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.760400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.801200</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.723300</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.685500</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.736700</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.739400</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.765900</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.694600</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.819800</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.725300</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.751200</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.692300</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.695300</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.769100</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.842900</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.757800</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.784500</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.770700</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.754000</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.780700</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.841800</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.770400</td>\n    </tr>\n    <tr>\n      <td>1410</td>\n      <td>0.690700</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.735400</td>\n    </tr>\n    <tr>\n      <td>1430</td>\n      <td>0.664800</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.724200</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.670300</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.761000</td>\n    </tr>\n    <tr>\n      <td>1470</td>\n      <td>0.790800</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.743300</td>\n    </tr>\n    <tr>\n      <td>1490</td>\n      <td>0.705200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.777400</td>\n    </tr>\n    <tr>\n      <td>1510</td>\n      <td>0.698700</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>0.769500</td>\n    </tr>\n    <tr>\n      <td>1530</td>\n      <td>0.769100</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>0.719900</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.686200</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>0.641600</td>\n    </tr>\n    <tr>\n      <td>1570</td>\n      <td>0.726800</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>0.746000</td>\n    </tr>\n    <tr>\n      <td>1590</td>\n      <td>0.775400</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.726100</td>\n    </tr>\n    <tr>\n      <td>1610</td>\n      <td>0.675100</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>0.766100</td>\n    </tr>\n    <tr>\n      <td>1630</td>\n      <td>0.746200</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>0.704700</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.712000</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>0.750500</td>\n    </tr>\n    <tr>\n      <td>1670</td>\n      <td>0.763300</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>0.675900</td>\n    </tr>\n    <tr>\n      <td>1690</td>\n      <td>0.707900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.731500</td>\n    </tr>\n    <tr>\n      <td>1710</td>\n      <td>0.786000</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>0.638400</td>\n    </tr>\n    <tr>\n      <td>1730</td>\n      <td>0.706200</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>0.704800</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.729200</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>0.758700</td>\n    </tr>\n    <tr>\n      <td>1770</td>\n      <td>0.664900</td>\n    </tr>\n    <tr>\n      <td>1780</td>\n      <td>0.663900</td>\n    </tr>\n    <tr>\n      <td>1790</td>\n      <td>0.702900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.675100</td>\n    </tr>\n    <tr>\n      <td>1810</td>\n      <td>0.686900</td>\n    </tr>\n    <tr>\n      <td>1820</td>\n      <td>0.719400</td>\n    </tr>\n    <tr>\n      <td>1830</td>\n      <td>0.704100</td>\n    </tr>\n    <tr>\n      <td>1840</td>\n      <td>0.708400</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.712800</td>\n    </tr>\n    <tr>\n      <td>1860</td>\n      <td>0.673200</td>\n    </tr>\n    <tr>\n      <td>1870</td>\n      <td>0.722300</td>\n    </tr>\n    <tr>\n      <td>1880</td>\n      <td>0.769800</td>\n    </tr>\n    <tr>\n      <td>1890</td>\n      <td>0.742000</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.760600</td>\n    </tr>\n    <tr>\n      <td>1910</td>\n      <td>0.751400</td>\n    </tr>\n    <tr>\n      <td>1920</td>\n      <td>0.683100</td>\n    </tr>\n    <tr>\n      <td>1930</td>\n      <td>0.617200</td>\n    </tr>\n    <tr>\n      <td>1940</td>\n      <td>0.594300</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.609300</td>\n    </tr>\n    <tr>\n      <td>1960</td>\n      <td>0.562600</td>\n    </tr>\n    <tr>\n      <td>1970</td>\n      <td>0.621000</td>\n    </tr>\n    <tr>\n      <td>1980</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>1990</td>\n      <td>0.575100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.586700</td>\n    </tr>\n    <tr>\n      <td>2010</td>\n      <td>0.594700</td>\n    </tr>\n    <tr>\n      <td>2020</td>\n      <td>0.559000</td>\n    </tr>\n    <tr>\n      <td>2030</td>\n      <td>0.576400</td>\n    </tr>\n    <tr>\n      <td>2040</td>\n      <td>0.586100</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.560200</td>\n    </tr>\n    <tr>\n      <td>2060</td>\n      <td>0.591800</td>\n    </tr>\n    <tr>\n      <td>2070</td>\n      <td>0.661300</td>\n    </tr>\n    <tr>\n      <td>2080</td>\n      <td>0.619200</td>\n    </tr>\n    <tr>\n      <td>2090</td>\n      <td>0.595200</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.538200</td>\n    </tr>\n    <tr>\n      <td>2110</td>\n      <td>0.611600</td>\n    </tr>\n    <tr>\n      <td>2120</td>\n      <td>0.566300</td>\n    </tr>\n    <tr>\n      <td>2130</td>\n      <td>0.580900</td>\n    </tr>\n    <tr>\n      <td>2140</td>\n      <td>0.627800</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.498700</td>\n    </tr>\n    <tr>\n      <td>2160</td>\n      <td>0.587700</td>\n    </tr>\n    <tr>\n      <td>2170</td>\n      <td>0.642100</td>\n    </tr>\n    <tr>\n      <td>2180</td>\n      <td>0.600500</td>\n    </tr>\n    <tr>\n      <td>2190</td>\n      <td>0.561200</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.590500</td>\n    </tr>\n    <tr>\n      <td>2210</td>\n      <td>0.536000</td>\n    </tr>\n    <tr>\n      <td>2220</td>\n      <td>0.634700</td>\n    </tr>\n    <tr>\n      <td>2230</td>\n      <td>0.562500</td>\n    </tr>\n    <tr>\n      <td>2240</td>\n      <td>0.566400</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.565600</td>\n    </tr>\n    <tr>\n      <td>2260</td>\n      <td>0.575500</td>\n    </tr>\n    <tr>\n      <td>2270</td>\n      <td>0.594200</td>\n    </tr>\n    <tr>\n      <td>2280</td>\n      <td>0.628600</td>\n    </tr>\n    <tr>\n      <td>2290</td>\n      <td>0.560500</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.610400</td>\n    </tr>\n    <tr>\n      <td>2310</td>\n      <td>0.582900</td>\n    </tr>\n    <tr>\n      <td>2320</td>\n      <td>0.481700</td>\n    </tr>\n    <tr>\n      <td>2330</td>\n      <td>0.625200</td>\n    </tr>\n    <tr>\n      <td>2340</td>\n      <td>0.556600</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.550800</td>\n    </tr>\n    <tr>\n      <td>2360</td>\n      <td>0.597900</td>\n    </tr>\n    <tr>\n      <td>2370</td>\n      <td>0.527900</td>\n    </tr>\n    <tr>\n      <td>2380</td>\n      <td>0.520300</td>\n    </tr>\n    <tr>\n      <td>2390</td>\n      <td>0.559600</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.569900</td>\n    </tr>\n    <tr>\n      <td>2410</td>\n      <td>0.604700</td>\n    </tr>\n    <tr>\n      <td>2420</td>\n      <td>0.599700</td>\n    </tr>\n    <tr>\n      <td>2430</td>\n      <td>0.560500</td>\n    </tr>\n    <tr>\n      <td>2440</td>\n      <td>0.610700</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.505000</td>\n    </tr>\n    <tr>\n      <td>2460</td>\n      <td>0.583700</td>\n    </tr>\n    <tr>\n      <td>2470</td>\n      <td>0.540300</td>\n    </tr>\n    <tr>\n      <td>2480</td>\n      <td>0.577300</td>\n    </tr>\n    <tr>\n      <td>2490</td>\n      <td>0.614600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.530500</td>\n    </tr>\n    <tr>\n      <td>2510</td>\n      <td>0.586800</td>\n    </tr>\n    <tr>\n      <td>2520</td>\n      <td>0.592900</td>\n    </tr>\n    <tr>\n      <td>2530</td>\n      <td>0.556800</td>\n    </tr>\n    <tr>\n      <td>2540</td>\n      <td>0.549400</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.624100</td>\n    </tr>\n    <tr>\n      <td>2560</td>\n      <td>0.537700</td>\n    </tr>\n    <tr>\n      <td>2570</td>\n      <td>0.525600</td>\n    </tr>\n    <tr>\n      <td>2580</td>\n      <td>0.574000</td>\n    </tr>\n    <tr>\n      <td>2590</td>\n      <td>0.549300</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.551500</td>\n    </tr>\n    <tr>\n      <td>2610</td>\n      <td>0.552100</td>\n    </tr>\n    <tr>\n      <td>2620</td>\n      <td>0.596600</td>\n    </tr>\n    <tr>\n      <td>2630</td>\n      <td>0.583000</td>\n    </tr>\n    <tr>\n      <td>2640</td>\n      <td>0.599100</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.549500</td>\n    </tr>\n    <tr>\n      <td>2660</td>\n      <td>0.540600</td>\n    </tr>\n    <tr>\n      <td>2670</td>\n      <td>0.608400</td>\n    </tr>\n    <tr>\n      <td>2680</td>\n      <td>0.588300</td>\n    </tr>\n    <tr>\n      <td>2690</td>\n      <td>0.565800</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.526100</td>\n    </tr>\n    <tr>\n      <td>2710</td>\n      <td>0.528600</td>\n    </tr>\n    <tr>\n      <td>2720</td>\n      <td>0.572200</td>\n    </tr>\n    <tr>\n      <td>2730</td>\n      <td>0.576900</td>\n    </tr>\n    <tr>\n      <td>2740</td>\n      <td>0.617500</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.535100</td>\n    </tr>\n    <tr>\n      <td>2760</td>\n      <td>0.595900</td>\n    </tr>\n    <tr>\n      <td>2770</td>\n      <td>0.527300</td>\n    </tr>\n    <tr>\n      <td>2780</td>\n      <td>0.536500</td>\n    </tr>\n    <tr>\n      <td>2790</td>\n      <td>0.574600</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.634100</td>\n    </tr>\n    <tr>\n      <td>2810</td>\n      <td>0.545000</td>\n    </tr>\n    <tr>\n      <td>2820</td>\n      <td>0.568400</td>\n    </tr>\n    <tr>\n      <td>2830</td>\n      <td>0.613700</td>\n    </tr>\n    <tr>\n      <td>2840</td>\n      <td>0.553500</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.521800</td>\n    </tr>\n    <tr>\n      <td>2860</td>\n      <td>0.575300</td>\n    </tr>\n    <tr>\n      <td>2870</td>\n      <td>0.585200</td>\n    </tr>\n    <tr>\n      <td>2880</td>\n      <td>0.617800</td>\n    </tr>\n    <tr>\n      <td>2890</td>\n      <td>0.497300</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.433700</td>\n    </tr>\n    <tr>\n      <td>2910</td>\n      <td>0.443000</td>\n    </tr>\n    <tr>\n      <td>2920</td>\n      <td>0.486600</td>\n    </tr>\n    <tr>\n      <td>2930</td>\n      <td>0.425300</td>\n    </tr>\n    <tr>\n      <td>2940</td>\n      <td>0.443100</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.510100</td>\n    </tr>\n    <tr>\n      <td>2960</td>\n      <td>0.478200</td>\n    </tr>\n    <tr>\n      <td>2970</td>\n      <td>0.464500</td>\n    </tr>\n    <tr>\n      <td>2980</td>\n      <td>0.448200</td>\n    </tr>\n    <tr>\n      <td>2990</td>\n      <td>0.439100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.465300</td>\n    </tr>\n    <tr>\n      <td>3010</td>\n      <td>0.459200</td>\n    </tr>\n    <tr>\n      <td>3020</td>\n      <td>0.440100</td>\n    </tr>\n    <tr>\n      <td>3030</td>\n      <td>0.474200</td>\n    </tr>\n    <tr>\n      <td>3040</td>\n      <td>0.432200</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>0.445500</td>\n    </tr>\n    <tr>\n      <td>3060</td>\n      <td>0.457700</td>\n    </tr>\n    <tr>\n      <td>3070</td>\n      <td>0.455900</td>\n    </tr>\n    <tr>\n      <td>3080</td>\n      <td>0.482600</td>\n    </tr>\n    <tr>\n      <td>3090</td>\n      <td>0.502600</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.439900</td>\n    </tr>\n    <tr>\n      <td>3110</td>\n      <td>0.488600</td>\n    </tr>\n    <tr>\n      <td>3120</td>\n      <td>0.405300</td>\n    </tr>\n    <tr>\n      <td>3130</td>\n      <td>0.497600</td>\n    </tr>\n    <tr>\n      <td>3140</td>\n      <td>0.465600</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>0.461300</td>\n    </tr>\n    <tr>\n      <td>3160</td>\n      <td>0.405300</td>\n    </tr>\n    <tr>\n      <td>3170</td>\n      <td>0.399200</td>\n    </tr>\n    <tr>\n      <td>3180</td>\n      <td>0.428300</td>\n    </tr>\n    <tr>\n      <td>3190</td>\n      <td>0.459600</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.470200</td>\n    </tr>\n    <tr>\n      <td>3210</td>\n      <td>0.484200</td>\n    </tr>\n    <tr>\n      <td>3220</td>\n      <td>0.444300</td>\n    </tr>\n    <tr>\n      <td>3230</td>\n      <td>0.476300</td>\n    </tr>\n    <tr>\n      <td>3240</td>\n      <td>0.451800</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.444900</td>\n    </tr>\n    <tr>\n      <td>3260</td>\n      <td>0.433700</td>\n    </tr>\n    <tr>\n      <td>3270</td>\n      <td>0.467800</td>\n    </tr>\n    <tr>\n      <td>3280</td>\n      <td>0.388900</td>\n    </tr>\n    <tr>\n      <td>3290</td>\n      <td>0.491000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.442700</td>\n    </tr>\n    <tr>\n      <td>3310</td>\n      <td>0.463700</td>\n    </tr>\n    <tr>\n      <td>3320</td>\n      <td>0.413800</td>\n    </tr>\n    <tr>\n      <td>3330</td>\n      <td>0.473100</td>\n    </tr>\n    <tr>\n      <td>3340</td>\n      <td>0.483800</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>0.567200</td>\n    </tr>\n    <tr>\n      <td>3360</td>\n      <td>0.426100</td>\n    </tr>\n    <tr>\n      <td>3370</td>\n      <td>0.459700</td>\n    </tr>\n    <tr>\n      <td>3380</td>\n      <td>0.488400</td>\n    </tr>\n    <tr>\n      <td>3390</td>\n      <td>0.436200</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.474200</td>\n    </tr>\n    <tr>\n      <td>3410</td>\n      <td>0.429300</td>\n    </tr>\n    <tr>\n      <td>3420</td>\n      <td>0.452600</td>\n    </tr>\n    <tr>\n      <td>3430</td>\n      <td>0.430800</td>\n    </tr>\n    <tr>\n      <td>3440</td>\n      <td>0.459000</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>0.411600</td>\n    </tr>\n    <tr>\n      <td>3460</td>\n      <td>0.424400</td>\n    </tr>\n    <tr>\n      <td>3470</td>\n      <td>0.454100</td>\n    </tr>\n    <tr>\n      <td>3480</td>\n      <td>0.444300</td>\n    </tr>\n    <tr>\n      <td>3490</td>\n      <td>0.436400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.451900</td>\n    </tr>\n    <tr>\n      <td>3510</td>\n      <td>0.456700</td>\n    </tr>\n    <tr>\n      <td>3520</td>\n      <td>0.446600</td>\n    </tr>\n    <tr>\n      <td>3530</td>\n      <td>0.480500</td>\n    </tr>\n    <tr>\n      <td>3540</td>\n      <td>0.446500</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>0.421700</td>\n    </tr>\n    <tr>\n      <td>3560</td>\n      <td>0.473700</td>\n    </tr>\n    <tr>\n      <td>3570</td>\n      <td>0.448000</td>\n    </tr>\n    <tr>\n      <td>3580</td>\n      <td>0.393000</td>\n    </tr>\n    <tr>\n      <td>3590</td>\n      <td>0.514600</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.498200</td>\n    </tr>\n    <tr>\n      <td>3610</td>\n      <td>0.434400</td>\n    </tr>\n    <tr>\n      <td>3620</td>\n      <td>0.403300</td>\n    </tr>\n    <tr>\n      <td>3630</td>\n      <td>0.396200</td>\n    </tr>\n    <tr>\n      <td>3640</td>\n      <td>0.453200</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>0.391300</td>\n    </tr>\n    <tr>\n      <td>3660</td>\n      <td>0.402100</td>\n    </tr>\n    <tr>\n      <td>3670</td>\n      <td>0.436200</td>\n    </tr>\n    <tr>\n      <td>3680</td>\n      <td>0.430900</td>\n    </tr>\n    <tr>\n      <td>3690</td>\n      <td>0.443400</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.406300</td>\n    </tr>\n    <tr>\n      <td>3710</td>\n      <td>0.415000</td>\n    </tr>\n    <tr>\n      <td>3720</td>\n      <td>0.408200</td>\n    </tr>\n    <tr>\n      <td>3730</td>\n      <td>0.467200</td>\n    </tr>\n    <tr>\n      <td>3740</td>\n      <td>0.425700</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>0.423700</td>\n    </tr>\n    <tr>\n      <td>3760</td>\n      <td>0.437300</td>\n    </tr>\n    <tr>\n      <td>3770</td>\n      <td>0.459100</td>\n    </tr>\n    <tr>\n      <td>3780</td>\n      <td>0.471900</td>\n    </tr>\n    <tr>\n      <td>3790</td>\n      <td>0.485800</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.442300</td>\n    </tr>\n    <tr>\n      <td>3810</td>\n      <td>0.452100</td>\n    </tr>\n    <tr>\n      <td>3820</td>\n      <td>0.435000</td>\n    </tr>\n    <tr>\n      <td>3830</td>\n      <td>0.431400</td>\n    </tr>\n    <tr>\n      <td>3840</td>\n      <td>0.434000</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>0.436800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3852, training_loss=0.7965007841525172, metrics={'train_runtime': 6610.4806, 'train_samples_per_second': 67.532, 'train_steps_per_second': 0.583, 'total_flos': 3.46645761394752e+16, 'train_loss': 0.7965007841525172, 'epoch': 4.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def predict_article_category(article):\n    inputs = tokenizer(article, return_tensors='pt', truncation=True, padding=True, max_length=300)\n    with torch.no_grad():\n        logits = model(**inputs).logits\n    predicted_class = logits.argmax().item()\n    return label_encoder.inverse_transform([predicted_class])[0]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T18:04:54.223776Z","iopub.execute_input":"2024-09-28T18:04:54.224432Z","iopub.status.idle":"2024-09-28T18:04:54.230870Z","shell.execute_reply.started":"2024-09-28T18:04:54.224392Z","shell.execute_reply":"2024-09-28T18:04:54.229992Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def te(new_article):\n    predicted_category = predict_article_category(new_article)\n    return predicted_category","metadata":{"execution":{"iopub.status.busy":"2024-09-28T18:04:55.940543Z","iopub.execute_input":"2024-09-28T18:04:55.940957Z","iopub.status.idle":"2024-09-28T18:04:55.946604Z","shell.execute_reply.started":"2024-09-28T18:04:55.940921Z","shell.execute_reply":"2024-09-28T18:04:55.945758Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"ss.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T14:09:08.210735Z","iopub.execute_input":"2024-09-28T14:09:08.211061Z","iopub.status.idle":"2024-09-28T14:09:08.225270Z","shell.execute_reply.started":"2024-09-28T14:09:08.211027Z","shell.execute_reply":"2024-09-28T14:09:08.224367Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"               target          Index\n0  academic interests    Article_502\n1  academic interests   Article_4578\n2  academic interests   Article_4589\n3    arts and culture  Article_11709\n4    arts and culture  Article_12270","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>academic interests</td>\n      <td>Article_502</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>academic interests</td>\n      <td>Article_4578</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>academic interests</td>\n      <td>Article_4589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arts and culture</td>\n      <td>Article_11709</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts and culture</td>\n      <td>Article_12270</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"ss","metadata":{"execution":{"iopub.status.busy":"2024-09-28T14:09:53.878784Z","iopub.execute_input":"2024-09-28T14:09:53.879170Z","iopub.status.idle":"2024-09-28T14:09:53.892955Z","shell.execute_reply.started":"2024-09-28T14:09:53.879132Z","shell.execute_reply":"2024-09-28T14:09:53.891988Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                       target           Index\n0                          academic interests     Article_502\n1                          academic interests    Article_4578\n2                          academic interests    Article_4589\n3                            arts and culture   Article_11709\n4                            arts and culture   Article_12270\n5                        books and literature   Article_17367\n6                        books and literature   Article_20404\n7                        business and finance   Article_25194\n8                                     careers   Article_29227\n9                             food and drinks   Article_31560\n10                            food and drinks   Article_32597\n11                      hobbies and interests   Article_34609\n12                                       pets   Article_44442\n13  pharmaceuticals, conditions, and symptoms   Article_45334\n14  pharmaceuticals, conditions, and symptoms   Article_49613\n15                                real estate   Article_53886\n16                                real estate   Article_53916\n17                                     sports   Article_58324\n18                          style and fashion   Article_63523\n19                               video gaming   Article_70861\n20                                     sports   Article_73561\n21                       books and literature   Article_74537\n22                   technology and computing   Article_78228\n23                                     health   Article_86929\n24                   family and relationships   Article_98973\n25                            home and garden  Article_104106\n26                         academic interests  Article_107501\n27                       business and finance  Article_112762\n28                                    careers  Article_113873\n29                      hobbies and interests  Article_117521\n30                            music and audio  Article_120892\n31                          news and politics  Article_121793\n32                           personal finance  Article_121890\n33                           personal finance  Article_122232\n34                                       pets  Article_125151\n35                                   shopping  Article_127440\n36                                 television  Article_130678\n37                                     travel  Article_131489\n38                                     travel  Article_131500\n39                               video gaming  Article_132882\n40                          news and politics  Article_137251\n41                                automotives  Article_141440\n42                                automotives  Article_141496\n43                          style and fashion  Article_144727\n44                                   shopping  Article_148153\n45                             healthy living  Article_150696\n46                            home and garden  Article_156302\n47                             healthy living  Article_164137\n48                                     movies  Article_166237\n49                                     movies  Article_166582","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>academic interests</td>\n      <td>Article_502</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>academic interests</td>\n      <td>Article_4578</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>academic interests</td>\n      <td>Article_4589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arts and culture</td>\n      <td>Article_11709</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts and culture</td>\n      <td>Article_12270</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>books and literature</td>\n      <td>Article_17367</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>books and literature</td>\n      <td>Article_20404</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>business and finance</td>\n      <td>Article_25194</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>careers</td>\n      <td>Article_29227</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>food and drinks</td>\n      <td>Article_31560</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>food and drinks</td>\n      <td>Article_32597</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>hobbies and interests</td>\n      <td>Article_34609</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pets</td>\n      <td>Article_44442</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>pharmaceuticals, conditions, and symptoms</td>\n      <td>Article_45334</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>pharmaceuticals, conditions, and symptoms</td>\n      <td>Article_49613</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>real estate</td>\n      <td>Article_53886</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>real estate</td>\n      <td>Article_53916</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>sports</td>\n      <td>Article_58324</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>style and fashion</td>\n      <td>Article_63523</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>video gaming</td>\n      <td>Article_70861</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>sports</td>\n      <td>Article_73561</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>books and literature</td>\n      <td>Article_74537</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>technology and computing</td>\n      <td>Article_78228</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>health</td>\n      <td>Article_86929</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>family and relationships</td>\n      <td>Article_98973</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>home and garden</td>\n      <td>Article_104106</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>academic interests</td>\n      <td>Article_107501</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>business and finance</td>\n      <td>Article_112762</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>careers</td>\n      <td>Article_113873</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>hobbies and interests</td>\n      <td>Article_117521</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>music and audio</td>\n      <td>Article_120892</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>news and politics</td>\n      <td>Article_121793</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>personal finance</td>\n      <td>Article_121890</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>personal finance</td>\n      <td>Article_122232</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>pets</td>\n      <td>Article_125151</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>shopping</td>\n      <td>Article_127440</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>television</td>\n      <td>Article_130678</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>travel</td>\n      <td>Article_131489</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>travel</td>\n      <td>Article_131500</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>video gaming</td>\n      <td>Article_132882</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>news and politics</td>\n      <td>Article_137251</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>automotives</td>\n      <td>Article_141440</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>automotives</td>\n      <td>Article_141496</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>style and fashion</td>\n      <td>Article_144727</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>shopping</td>\n      <td>Article_148153</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>healthy living</td>\n      <td>Article_150696</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>home and garden</td>\n      <td>Article_156302</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>healthy living</td>\n      <td>Article_164137</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>movies</td>\n      <td>Article_166237</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>movies</td>\n      <td>Article_166582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T14:09:08.367972Z","iopub.execute_input":"2024-09-28T14:09:08.368270Z","iopub.status.idle":"2024-09-28T14:09:08.378662Z","shell.execute_reply.started":"2024-09-28T14:09:08.368236Z","shell.execute_reply":"2024-09-28T14:09:08.377733Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                text  Word Count      Index\n0  equl offers enzyme assay kits, reagent mixture...         353  Article_0\n1  gauthmath: instant math questions solver for f...         112  Article_1\n2  Whats the No. 1 cause of blindness in older ad...         340  Article_2\n3  Surfers will ride a wave in the Amazon this we...         465  Article_3\n4  Why is the top of a leaf the most colorful, so...         269  Article_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Word Count</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>equl offers enzyme assay kits, reagent mixture...</td>\n      <td>353</td>\n      <td>Article_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gauthmath: instant math questions solver for f...</td>\n      <td>112</td>\n      <td>Article_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Whats the No. 1 cause of blindness in older ad...</td>\n      <td>340</td>\n      <td>Article_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Surfers will ride a wave in the Amazon this we...</td>\n      <td>465</td>\n      <td>Article_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why is the top of a leaf the most colorful, so...</td>\n      <td>269</td>\n      <td>Article_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import torch\n\n# Assuming you have already loaded your model and tokenizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)  # Move the model to the appropriate device\n\ndef predict_article_category(article):\n    inputs = tokenizer(article, return_tensors='pt', truncation=True, padding=True, max_length=290)\n    \n    # Move inputs to the same device as the model\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    \n    with torch.no_grad():\n        logits = model(**inputs).logits\n    \n    predicted_class = logits.argmax().item()\n    return label_encoder.inverse_transform([predicted_class])[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T18:05:01.748450Z","iopub.execute_input":"2024-09-28T18:05:01.749112Z","iopub.status.idle":"2024-09-28T18:05:01.758967Z","shell.execute_reply.started":"2024-09-28T18:05:01.749065Z","shell.execute_reply":"2024-09-28T18:05:01.758146Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"mm = test['text'].apply(te)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T18:05:02.137217Z","iopub.execute_input":"2024-09-28T18:05:02.137597Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mm","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:22:11.899372Z","iopub.execute_input":"2024-09-28T15:22:11.900329Z","iopub.status.idle":"2024-09-28T15:22:11.910726Z","shell.execute_reply.started":"2024-09-28T15:22:11.900284Z","shell.execute_reply":"2024-09-28T15:22:11.909635Z"},"trusted":true},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0         academic interests\n1         academic interests\n2                     health\n3          news and politics\n4         academic interests\n                 ...        \n174377          video gaming\n174378          video gaming\n174379          video gaming\n174380          video gaming\n174381          video gaming\nName: text, Length: 174382, dtype: object"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-09-28T14:47:03.610649Z","iopub.execute_input":"2024-09-28T14:47:03.611316Z","iopub.status.idle":"2024-09-28T14:47:03.624681Z","shell.execute_reply.started":"2024-09-28T14:47:03.611273Z","shell.execute_reply":"2024-09-28T14:47:03.623763Z"},"trusted":true},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                                                     text  Word Count  \\\n0       equl offers enzyme assay kits, reagent mixture...         353   \n1       gauthmath: instant math questions solver for f...         112   \n2       Whats the No. 1 cause of blindness in older ad...         340   \n3       Surfers will ride a wave in the Amazon this we...         465   \n4       Why is the top of a leaf the most colorful, so...         269   \n...                                                   ...         ...   \n174377  his story will soon pale in comparison next to...         119   \n174378  Mundo.Take a look at a gallery of covers below...         115   \n174379  may change over the course of the game's devel...         141   \n174380  Mark Gustafson. If you've already watched it a...         101   \n174381  Mann/Tomeu MoreyPoison Ivy #7 by David Nakayam...         160   \n\n                 Index  \n0            Article_0  \n1            Article_1  \n2            Article_2  \n3            Article_3  \n4            Article_4  \n...                ...  \n174377  Article_174377  \n174378  Article_174378  \n174379  Article_174379  \n174380  Article_174380  \n174381  Article_174381  \n\n[174382 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Word Count</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>equl offers enzyme assay kits, reagent mixture...</td>\n      <td>353</td>\n      <td>Article_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gauthmath: instant math questions solver for f...</td>\n      <td>112</td>\n      <td>Article_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Whats the No. 1 cause of blindness in older ad...</td>\n      <td>340</td>\n      <td>Article_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Surfers will ride a wave in the Amazon this we...</td>\n      <td>465</td>\n      <td>Article_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why is the top of a leaf the most colorful, so...</td>\n      <td>269</td>\n      <td>Article_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>174377</th>\n      <td>his story will soon pale in comparison next to...</td>\n      <td>119</td>\n      <td>Article_174377</td>\n    </tr>\n    <tr>\n      <th>174378</th>\n      <td>Mundo.Take a look at a gallery of covers below...</td>\n      <td>115</td>\n      <td>Article_174378</td>\n    </tr>\n    <tr>\n      <th>174379</th>\n      <td>may change over the course of the game's devel...</td>\n      <td>141</td>\n      <td>Article_174379</td>\n    </tr>\n    <tr>\n      <th>174380</th>\n      <td>Mark Gustafson. If you've already watched it a...</td>\n      <td>101</td>\n      <td>Article_174380</td>\n    </tr>\n    <tr>\n      <th>174381</th>\n      <td>Mann/Tomeu MoreyPoison Ivy #7 by David Nakayam...</td>\n      <td>160</td>\n      <td>Article_174381</td>\n    </tr>\n  </tbody>\n</table>\n<p>174382 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"ss['id']  = test['Index']","metadata":{"execution":{"iopub.status.busy":"2024-09-28T14:47:15.546648Z","iopub.execute_input":"2024-09-28T14:47:15.547277Z","iopub.status.idle":"2024-09-28T14:47:15.553464Z","shell.execute_reply.started":"2024-09-28T14:47:15.547235Z","shell.execute_reply":"2024-09-28T14:47:15.552474Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"s = pd.read_csv('/kaggle/input/hacke-earth-fibe/dataset/sample_submission.csv')\ns","metadata":{"execution":{"iopub.status.busy":"2024-09-28T14:47:59.253193Z","iopub.execute_input":"2024-09-28T14:47:59.254469Z","iopub.status.idle":"2024-09-28T14:47:59.286320Z","shell.execute_reply.started":"2024-09-28T14:47:59.254395Z","shell.execute_reply":"2024-09-28T14:47:59.285413Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                       target           Index\n0                          academic interests     Article_502\n1                          academic interests    Article_4578\n2                          academic interests    Article_4589\n3                            arts and culture   Article_11709\n4                            arts and culture   Article_12270\n5                        books and literature   Article_17367\n6                        books and literature   Article_20404\n7                        business and finance   Article_25194\n8                                     careers   Article_29227\n9                             food and drinks   Article_31560\n10                            food and drinks   Article_32597\n11                      hobbies and interests   Article_34609\n12                                       pets   Article_44442\n13  pharmaceuticals, conditions, and symptoms   Article_45334\n14  pharmaceuticals, conditions, and symptoms   Article_49613\n15                                real estate   Article_53886\n16                                real estate   Article_53916\n17                                     sports   Article_58324\n18                          style and fashion   Article_63523\n19                               video gaming   Article_70861\n20                                     sports   Article_73561\n21                       books and literature   Article_74537\n22                   technology and computing   Article_78228\n23                                     health   Article_86929\n24                   family and relationships   Article_98973\n25                            home and garden  Article_104106\n26                         academic interests  Article_107501\n27                       business and finance  Article_112762\n28                                    careers  Article_113873\n29                      hobbies and interests  Article_117521\n30                            music and audio  Article_120892\n31                          news and politics  Article_121793\n32                           personal finance  Article_121890\n33                           personal finance  Article_122232\n34                                       pets  Article_125151\n35                                   shopping  Article_127440\n36                                 television  Article_130678\n37                                     travel  Article_131489\n38                                     travel  Article_131500\n39                               video gaming  Article_132882\n40                          news and politics  Article_137251\n41                                automotives  Article_141440\n42                                automotives  Article_141496\n43                          style and fashion  Article_144727\n44                                   shopping  Article_148153\n45                             healthy living  Article_150696\n46                            home and garden  Article_156302\n47                             healthy living  Article_164137\n48                                     movies  Article_166237\n49                                     movies  Article_166582","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>academic interests</td>\n      <td>Article_502</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>academic interests</td>\n      <td>Article_4578</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>academic interests</td>\n      <td>Article_4589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arts and culture</td>\n      <td>Article_11709</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts and culture</td>\n      <td>Article_12270</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>books and literature</td>\n      <td>Article_17367</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>books and literature</td>\n      <td>Article_20404</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>business and finance</td>\n      <td>Article_25194</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>careers</td>\n      <td>Article_29227</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>food and drinks</td>\n      <td>Article_31560</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>food and drinks</td>\n      <td>Article_32597</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>hobbies and interests</td>\n      <td>Article_34609</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pets</td>\n      <td>Article_44442</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>pharmaceuticals, conditions, and symptoms</td>\n      <td>Article_45334</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>pharmaceuticals, conditions, and symptoms</td>\n      <td>Article_49613</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>real estate</td>\n      <td>Article_53886</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>real estate</td>\n      <td>Article_53916</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>sports</td>\n      <td>Article_58324</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>style and fashion</td>\n      <td>Article_63523</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>video gaming</td>\n      <td>Article_70861</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>sports</td>\n      <td>Article_73561</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>books and literature</td>\n      <td>Article_74537</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>technology and computing</td>\n      <td>Article_78228</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>health</td>\n      <td>Article_86929</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>family and relationships</td>\n      <td>Article_98973</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>home and garden</td>\n      <td>Article_104106</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>academic interests</td>\n      <td>Article_107501</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>business and finance</td>\n      <td>Article_112762</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>careers</td>\n      <td>Article_113873</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>hobbies and interests</td>\n      <td>Article_117521</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>music and audio</td>\n      <td>Article_120892</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>news and politics</td>\n      <td>Article_121793</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>personal finance</td>\n      <td>Article_121890</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>personal finance</td>\n      <td>Article_122232</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>pets</td>\n      <td>Article_125151</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>shopping</td>\n      <td>Article_127440</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>television</td>\n      <td>Article_130678</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>travel</td>\n      <td>Article_131489</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>travel</td>\n      <td>Article_131500</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>video gaming</td>\n      <td>Article_132882</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>news and politics</td>\n      <td>Article_137251</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>automotives</td>\n      <td>Article_141440</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>automotives</td>\n      <td>Article_141496</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>style and fashion</td>\n      <td>Article_144727</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>shopping</td>\n      <td>Article_148153</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>healthy living</td>\n      <td>Article_150696</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>home and garden</td>\n      <td>Article_156302</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>healthy living</td>\n      <td>Article_164137</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>movies</td>\n      <td>Article_166237</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>movies</td>\n      <td>Article_166582</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:23:07.244078Z","iopub.execute_input":"2024-09-28T15:23:07.244564Z","iopub.status.idle":"2024-09-28T15:23:07.257739Z","shell.execute_reply.started":"2024-09-28T15:23:07.244499Z","shell.execute_reply":"2024-09-28T15:23:07.256439Z"},"trusted":true},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                                                text  Word Count      Index\n0  equl offers enzyme assay kits, reagent mixture...         353  Article_0\n1  gauthmath: instant math questions solver for f...         112  Article_1\n2  Whats the No. 1 cause of blindness in older ad...         340  Article_2\n3  Surfers will ride a wave in the Amazon this we...         465  Article_3\n4  Why is the top of a leaf the most colorful, so...         269  Article_4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Word Count</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>equl offers enzyme assay kits, reagent mixture...</td>\n      <td>353</td>\n      <td>Article_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gauthmath: instant math questions solver for f...</td>\n      <td>112</td>\n      <td>Article_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Whats the No. 1 cause of blindness in older ad...</td>\n      <td>340</td>\n      <td>Article_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Surfers will ride a wave in the Amazon this we...</td>\n      <td>465</td>\n      <td>Article_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why is the top of a leaf the most colorful, so...</td>\n      <td>269</td>\n      <td>Article_4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"ss = pd.DataFrame()\nss['target'] = mm\nss['Index'] = test['Index']","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:26:17.472585Z","iopub.execute_input":"2024-09-28T15:26:17.472966Z","iopub.status.idle":"2024-09-28T15:26:17.486929Z","shell.execute_reply.started":"2024-09-28T15:26:17.472931Z","shell.execute_reply":"2024-09-28T15:26:17.485956Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"ss.to_csv('sub_nlp_new.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:26:24.247349Z","iopub.execute_input":"2024-09-28T15:26:24.247791Z","iopub.status.idle":"2024-09-28T15:26:24.594121Z","shell.execute_reply.started":"2024-09-28T15:26:24.247750Z","shell.execute_reply":"2024-09-28T15:26:24.593107Z"},"trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"ss","metadata":{"execution":{"iopub.status.busy":"2024-09-28T15:26:18.753087Z","iopub.execute_input":"2024-09-28T15:26:18.753504Z","iopub.status.idle":"2024-09-28T15:26:18.765691Z","shell.execute_reply.started":"2024-09-28T15:26:18.753466Z","shell.execute_reply":"2024-09-28T15:26:18.764682Z"},"trusted":true},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                    target           Index\n0       academic interests       Article_0\n1       academic interests       Article_1\n2                   health       Article_2\n3        news and politics       Article_3\n4       academic interests       Article_4\n...                    ...             ...\n174377        video gaming  Article_174377\n174378        video gaming  Article_174378\n174379        video gaming  Article_174379\n174380        video gaming  Article_174380\n174381        video gaming  Article_174381\n\n[174382 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>academic interests</td>\n      <td>Article_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>academic interests</td>\n      <td>Article_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>health</td>\n      <td>Article_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>news and politics</td>\n      <td>Article_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>academic interests</td>\n      <td>Article_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>174377</th>\n      <td>video gaming</td>\n      <td>Article_174377</td>\n    </tr>\n    <tr>\n      <th>174378</th>\n      <td>video gaming</td>\n      <td>Article_174378</td>\n    </tr>\n    <tr>\n      <th>174379</th>\n      <td>video gaming</td>\n      <td>Article_174379</td>\n    </tr>\n    <tr>\n      <th>174380</th>\n      <td>video gaming</td>\n      <td>Article_174380</td>\n    </tr>\n    <tr>\n      <th>174381</th>\n      <td>video gaming</td>\n      <td>Article_174381</td>\n    </tr>\n  </tbody>\n</table>\n<p>174382 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}